import re
import logging
from uuid import UUID
from fuzzywuzzy import fuzz
from backend.models.database import get_supabase_client
from backend.utils.normalizers import (
    normalize_sku, normalize_name, extract_pipe_size, extract_fitting_size,
    extract_thread_size
)
from backend.config import settings
from backend.models.schemas import MatchResult
from backend.services.embeddings import get_embedding_matcher
from backend.services.llm_matcher import get_llm_matcher

logger = logging.getLogger(__name__)


def detect_client_category(client_name: str) -> str | None:
    """
    –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞.
    Returns: 'prestige', 'outdoor', 'ppr', 'sewer', –∏–ª–∏ None
    """
    name = client_name.lower()

    is_sewer = any(x in name for x in ['–∫–∞–Ω', '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü', '—Å–∞–Ω—Ç–µ—Ö'])

    # –ú–∞–ª–æ—à—É–º–Ω–∞—è/Prestige = –±–µ–ª–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è (403)
    if any(x in name for x in ['–º–∞–ª–æ—à—É–º', 'prestige']):
        return 'prestige'
    # –ë–µ–ª–∞—è + –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è = —Ç–æ–∂–µ Prestige
    if is_sewer and '–±–µ–ª' in name:
        return 'prestige'

    # –ù–∞—Ä—É–∂–Ω–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è = —Ä—ã–∂–∞—è (303)
    if any(x in name for x in ['–Ω–∞—Ä –∫–∞–Ω', '–Ω–∞—Ä.–∫–∞–Ω', '–Ω–∞—Ä—É–∂–Ω', '—Ä—ã–∂']):
        return 'outdoor'

    # –ü–ü–† (–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥/–æ—Ç–æ–ø–ª–µ–Ω–∏–µ) - –±–µ–ª—ã–π, –Ω–æ –ù–ï –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è
    # "–ü–ü" = –ø–æ–ª–∏–ø—Ä–æ–ø–∏–ª–µ–Ω = –ü–ü–†
    if any(x in name for x in ['–ø–ø—Ä', 'ppr', '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥', '–æ—Ç–æ–ø–ª–µ–Ω', ' –ø–ø ', '–ø–ø ']):
        return 'ppr'
    if '–±–µ–ª' in name and not is_sewer:
        return 'ppr'

    # –û–±—ã—á–Ω–∞—è —Å–µ—Ä–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è (202)
    if is_sewer or '—Å–µ—Ä' in name:
        return 'sewer'

    return None  # –ù–µ —É–∫–∞–∑–∞–Ω–æ - –¥–µ—Ñ–æ–ª—Ç: –æ–±—ã—á–Ω–∞—è —Å–µ—Ä–∞—è –∫–∞–Ω.


def extract_product_type(name: str) -> str | None:
    """
    –ò–∑–≤–ª–µ—á—å —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è.
    Returns: '—Ç—Ä—É–±–∞', '–æ—Ç–≤–æ–¥', '—Ç—Ä–æ–π–Ω–∏–∫', '–º—É—Ñ—Ç–∞', '–∑–∞–≥–ª—É—à–∫–∞', '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫',
             '—Ä–µ–≤–∏–∑–∏—è', '–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω–∞', '–ø–∞—Ç—Ä—É–±–æ–∫', '—Ö–æ–º—É—Ç', '–∫—Ä–∞–Ω', '—Ñ–∏–ª—å—Ç—Ä',
             '–∫–ª–∞–ø–∞–Ω', '—Å–∏—Ñ–æ–Ω' –∏–ª–∏ None
    """
    name_lower = name.lower()

    # –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω - –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–µ—Ä–≤—ã–µ
    # –í–ê–ñ–ù–û: "—Ä–µ–¥" –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –î–û "–º—É—Ñ—Ç", —Ç.–∫. "–ú—É—Ñ—Ç–∞ —Ä–µ–¥." = "–ú—É—Ñ—Ç–∞ –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫"
    types = [
        ('–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω', '–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω–∞'),
        ('—Ç—Ä–æ–π–Ω–∏–∫', '—Ç—Ä–æ–π–Ω–∏–∫'),
        ('–ø–µ—Ä–µ—Ö–æ–¥', '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫'),
        ('—Ä–µ–¥', '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫'),  # "—Ä–µ–¥." = —Ä–µ–¥—É–∫—Ü–∏–æ–Ω–Ω—ã–π = –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫
        ('—Ä–∞–∑—ä–µ–º–Ω', '–º—É—Ñ—Ç–∞'),  # –º—É—Ñ—Ç–∞ —Ä–∞–∑—ä–µ–º–Ω–∞—è = –∞–º–µ—Ä–∏–∫–∞–Ω–∫–∞
        ('–æ—Ç–≤–æ–¥', '–æ—Ç–≤–æ–¥'),
        ('–∫–æ–ª–µ–Ω–æ', '–æ—Ç–≤–æ–¥'),
        ('—É–≥–æ–ª', '–æ—Ç–≤–æ–¥'),
        ('–º—É—Ñ—Ç', '–º—É—Ñ—Ç–∞'),
        ('–∑–∞–≥–ª—É—à', '–∑–∞–≥–ª—É—à–∫–∞'),
        ('—Ä–µ–≤–∏–∑–∏', '—Ä–µ–≤–∏–∑–∏—è'),
        ('–ø–∞—Ç—Ä—É–±', '–ø–∞—Ç—Ä—É–±–æ–∫'),
        ('—Ç—Ä—É–±', '—Ç—Ä—É–±–∞'),
        ('—Ö–æ–º—É—Ç', '—Ö–æ–º—É—Ç'),
        ('–∫—Ä–∞–Ω', '–∫—Ä–∞–Ω'),
        ('—Ñ–∏–ª—å—Ç—Ä', '—Ñ–∏–ª—å—Ç—Ä'),
        ('–∫–ª–∞–ø–∞–Ω', '–∫–ª–∞–ø–∞–Ω'),
        ('—Å–∏—Ñ–æ–Ω', '—Å–∏—Ñ–æ–Ω'),
    ]

    for marker, ptype in types:
        if marker in name_lower:
            return ptype
    return None


def extract_angle(name: str) -> int | None:
    """–ò–∑–≤–ª–µ—á—å —É–≥–æ–ª –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è (15¬∞, 30¬∞, 45¬∞, 67¬∞, 87¬∞, 90¬∞)"""
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –≤—Å–µ —É–≥–ª—ã, –¥–∞–∂–µ –µ—Å–ª–∏ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –∏—Ö –Ω–µ—Ç
    m = re.search(r'\b(15|30|45|67|87|90)\s*[¬∞–≥—Ä–∞–¥—É—Å]?', name.lower())
    if m:
        return int(m.group(1))
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: /45, /90
    m = re.search(r'/\s*(15|30|45|67|87|90)\b', name.lower())
    if m:
        return int(m.group(1))
    return None


def normalize_angle(angle: int | None) -> int | None:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —É–≥–æ–ª –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –∫–∞—Ç–∞–ª–æ–≥—É Jakko.
    90¬∞ ‚Üí 87¬∞ (–≤ –∫–∞—Ç–∞–ª–æ–≥–µ Jakko –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 87¬∞ –≤–º–µ—Å—Ç–æ 90¬∞)
    """
    if angle is None:
        return None
    if angle == 90:
        return 87  # Jakko convention: 87¬∞ –≤–º–µ—Å—Ç–æ 90¬∞
    return angle


def filter_by_category(matches: list, client_cat: str | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
    matches: —Å–ø–∏—Å–æ–∫ (product, score) –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ product dicts
    """
    if not matches or len(matches) <= 1:
        return matches

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç: (product, score) –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ product
    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = None
    if client_cat == 'prestige':
        filtered = [m for m in matches
                    if '–º–∞–ª–æ—à—É–º' in get_product(m).get('category', '').lower()
                    or 'prestige' in get_product(m)['name'].lower()]
    elif client_cat == 'outdoor':
        filtered = [m for m in matches
                    if '–Ω–∞—Ä—É–∂–Ω' in get_product(m).get('category', '').lower()
                    or '–Ω–∞—Ä.–∫–∞–Ω' in get_product(m)['name'].lower()]
    elif client_cat == 'ppr':
        filtered = [m for m in matches
                    if '–ø–ø—Ä' in get_product(m).get('category', '').lower()
                    or '–ø–ø—Ä' in get_product(m)['name'].lower()]
    else:
        # –î–µ—Ñ–æ–ª—Ç: –æ–±—ã—á–Ω–∞—è –°–ï–†–ê–Ø –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è (202) - –∏—Å–∫–ª—é—á–∞–µ–º Prestige –∏ –Ω–∞—Ä—É–∂–Ω—É—é
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: SKU –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 202 (—Å–µ—Ä–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è)
        sku_202 = [m for m in matches
                   if get_product(m).get('sku', '').startswith('202')]
        if sku_202:
            return sku_202

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –ö–∞—Ç–µ–≥–æ—Ä–∏—è "–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è" (–Ω–µ –º–∞–ª–æ—à—É–º/–Ω–∞—Ä—É–∂–Ω–∞—è) –∏–ª–∏ "—Å–µ—Ä—ã–π" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        filtered = [m for m in matches
                    if ('–∫–∞–Ω–∞–ª–∏–∑–∞—Ü' in get_product(m).get('category', '').lower()
                        and '–º–∞–ª–æ—à—É–º' not in get_product(m).get('category', '').lower()
                        and '–Ω–∞—Ä—É–∂–Ω' not in get_product(m).get('category', '').lower())
                    or '—Å–µ—Ä—ã–π' in get_product(m)['name'].lower()]

    return filtered if filtered else matches


def filter_by_product_type(matches: list, client_type: str | None) -> list:
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ç–∏–ø—É —Ç–æ–≤–∞—Ä–∞ (–æ—Ç–≤–æ–¥, –º—É—Ñ—Ç–∞, –∑–∞–≥–ª—É—à–∫–∞ –∏ —Ç.–¥.)"""
    if not matches or not client_type or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if extract_product_type(get_product(m)['name']) == client_type]

    return filtered if filtered else matches


def filter_by_angle(matches: list, client_angle: int | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —É–≥–ª—É (15¬∞, 30¬∞, 45¬∞, 67¬∞, 87¬∞, 90¬∞).
    90¬∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç—Å—è –≤ 87¬∞ (Jakko convention).
    """
    if not matches or not client_angle or len(matches) <= 1:
        return matches

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —É–≥–æ–ª –∫–ª–∏–µ–Ω—Ç–∞ (90¬∞ ‚Üí 87¬∞)
    normalized_angle = normalize_angle(client_angle)

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if extract_angle(get_product(m)['name']) == normalized_angle]

    return filtered if filtered else matches


def extract_thread_type(name: str) -> str | None:
    """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø —Ä–µ–∑—å–±—ã: '–≤–Ω' (–≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è) –∏–ª–∏ '–Ω–∞—Ä' (–Ω–∞—Ä—É–∂–Ω–∞—è)"""
    name_lower = name.lower()
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã: –≤/—Ä, –≤–Ω.—Ä–µ–∑, –≤–Ω. —Ä–µ–∑, –≤–Ω—É—Ç—Ä
    if any(x in name_lower for x in ['–≤/—Ä', '–≤–Ω.—Ä–µ–∑', '–≤–Ω. —Ä–µ–∑', '–≤–Ω —Ä–µ–∑', '–≤–Ω—É—Ç—Ä']):
        return '–≤–Ω'
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã: –Ω/—Ä, –Ω–∞—Ä.—Ä–µ–∑, –Ω–∞—Ä. —Ä–µ–∑, –Ω–∞—Ä—É–∂
    if any(x in name_lower for x in ['–Ω/—Ä', '–Ω–∞—Ä.—Ä–µ–∑', '–Ω–∞—Ä. —Ä–µ–∑', '–Ω–∞—Ä —Ä–µ–∑', '–Ω–∞—Ä—É–∂']):
        return '–Ω–∞—Ä'
    return None


def filter_by_thread(matches: list, client_thread: str | None) -> list:
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ç–∏–ø—É —Ä–µ–∑—å–±—ã (–≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è/–Ω–∞—Ä—É–∂–Ω–∞—è)"""
    if not matches or not client_thread or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if extract_thread_type(get_product(m)['name']) == client_thread]

    return filtered if filtered else matches


def filter_by_fitting_size(matches: list, client_size: tuple | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º —Ñ–∏—Ç–∏–Ω–≥–∞ (110/50, 110/110 –∏ —Ç.–¥.)

    –õ–æ–≥–∏–∫–∞:
    - –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 2 —Ä–∞–∑–º–µ—Ä–∞ (110/50) - –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    - –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 1 —Ä–∞–∑–º–µ—Ä (110) - –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã (110-110),
      –µ—Å–ª–∏ –Ω–µ—Ç - —Ç–æ–≥–¥–∞ –∏—â–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É
    """
    if not matches or not client_size or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 2+ —Ä–∞–∑–º–µ—Ä–∞ - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if len(client_size) >= 2:
        # –î–ª—è 3 —Ä–∞–∑–º–µ—Ä–æ–≤ (—Ç—Ä–æ–π–Ω–∏–∫ –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫ 40-25-40) - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if len(client_size) == 3:
            filtered = [m for m in matches
                        if extract_fitting_size(get_product(m)['name']) == client_size]
            if filtered:
                return filtered
            # Fallback: –∏—â–µ–º —Ç—Ä–æ–π–Ω–∏–∫ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∫—Ä–∞–π–Ω–∏–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏
            outer1, inner, outer2 = client_size
            filtered = [m for m in matches
                        if (ps := extract_fitting_size(get_product(m)['name']))
                        and len(ps) >= 2
                        and ps[0] == outer1 and inner in ps]
            return filtered if filtered else matches

        # –î–ª—è 2 —Ä–∞–∑–º–µ—Ä–æ–≤ - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        filtered = [m for m in matches
                    if extract_fitting_size(get_product(m)['name']) == client_size]
        return filtered if filtered else matches

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 1 —Ä–∞–∑–º–µ—Ä (110) - –∏—â–µ–º —Ç–æ–≤–∞—Ä—ã —Å –û–î–ù–ò–ú —Ä–∞–∑–º–µ—Ä–æ–º –∏–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏
    single_size = client_size[0]

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –¢–æ–≤–∞—Ä—ã —Å –æ–¥–Ω–∏–º —Ä–∞–∑–º–µ—Ä–æ–º (–ø—Ä–æ—Å—Ç–æ 110, –±–µ–∑ –≤—Ç–æ—Ä–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞)
    # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –æ—Ç–≤–æ–¥–æ–≤: "–æ—Ç–≤–æ–¥ 110" != "–æ—Ç–≤–æ–¥ 110-50"
    single_only = [m for m in matches
                   if (ps := extract_fitting_size(get_product(m)['name']))
                   and len(ps) == 1 and ps[0] == single_size]
    if single_only:
        return single_only

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã (110-110, 50-50) - –ø—Ä—è–º–æ–π —Ç—Ä–æ–π–Ω–∏–∫/–º—É—Ñ—Ç–∞
    same_size = [m for m in matches
                 if extract_fitting_size(get_product(m)['name']) == (single_size, single_size)]
    if same_size:
        return same_size

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –ü–µ—Ä–≤—ã–π —Ä–∞–∑–º–µ—Ä —Å–æ–≤–ø–∞–¥–∞–µ—Ç (110-50, 110-110) - fallback
    first_match = [m for m in matches
                   if (ps := extract_fitting_size(get_product(m)['name']))
                   and ps[0] == single_size]
    return first_match if first_match else matches


def filter_by_thread_size(matches: list, client_thread: tuple | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ä–µ–∑—å–±—ã (32√ó1", 25√ó3/4" –∏ —Ç.–¥.)

    client_thread: (–º–º, –¥—é–π–º—ã) - –Ω–∞–ø—Ä–∏–º–µ—Ä (32, "1")
    """
    if not matches or not client_thread or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    mm, inches = client_thread
    # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã —Å —Ç–∞–∫–∏–º –∂–µ —Ä–∞–∑–º–µ—Ä–æ–º —Ä–µ–∑—å–±—ã –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
    # –§–æ—Ä–º–∞—Ç—ã –∫–∞—Ç–∞–ª–æ–≥–∞: "32x1"", "32√ó1"", "32*1""
    filtered = []
    for m in matches:
        name = get_product(m)['name'].lower()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Å —Ä–µ–∑—å–±–æ–π
        if (f'{mm}x{inches}"' in name or
            f'{mm}√ó{inches}"' in name or
            f'{mm}*{inches}"' in name or
            f'{mm}-{inches}"' in name):
            filtered.append(m)

    return filtered if filtered else matches


def is_eco_product(name: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–æ–≤–∞—Ä –≠–ö–û (—ç–∫–æ–Ω–æ–º) –≤–µ—Ä—Å–∏–µ–π.

    –¢–æ–ª—â–∏–Ω—ã —Å—Ç–µ–Ω–æ–∫:
    - (1.8) –¥–ª—è 32/40/50 –º–º = —Å—Ç–∞–Ω–¥–∞—Ä—Ç (–Ω–µ –≠–ö–û)
    - (2.2) –¥–ª—è 110 –º–º = –≠–ö–û (—Ç–æ–Ω–∫–æ—Å—Ç–µ–Ω–Ω–∞—è)
    - (2.7) –¥–ª—è 110 –º–º = —Å—Ç–∞–Ω–¥–∞—Ä—Ç
    """
    name_lower = name.lower()
    # (1.8) - —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è —Ç—Ä—É–± 32/40/50, —è–≤–Ω–æ –Ω–µ –≠–ö–û
    if '(1.8)' in name_lower:
        return False
    return '—ç–∫–æ' in name_lower or 'eko' in name_lower or '(2.2)' in name_lower


def extract_mm_from_clamp(client_name: str) -> int | None:
    """–ò–∑–≤–ª–µ—á—å —Ä–∞–∑–º–µ—Ä –≤ –º–º –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —Ö–æ–º—É—Ç–∞"""
    name = client_name.lower()
    if '—Ö–æ–º—É—Ç' not in name:
        return None
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã: "—Ö–æ–º—É—Ç 110", "—Ö–æ–º—É—Ç –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ 110"
    m = re.search(r'\b—Ö–æ–º—É—Ç\s+(?:–≤\s+–∫–æ–º–ø–ª–µ–∫—Ç–µ\s+)?(\d+)\b', name)
    if m:
        mm = int(m.group(1))
        # –í–∞–ª–∏–¥–∞—Ü–∏—è: —Ä–∞–∑–º–µ—Ä—ã —Ö–æ–º—É—Ç–æ–≤ 15-200–º–º
        if 15 <= mm <= 200:
            return mm
    return None


def clamp_fits_mm(product_name: str, target_mm: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —Ö–æ–º—É—Ç –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –º–º"""
    # –§–æ—Ä–º–∞—Ç: (107-115) –∏–ª–∏ (87-92)
    m = re.search(r'\((\d+)-(\d+)\)', product_name)
    if m:
        mm_min, mm_max = int(m.group(1)), int(m.group(2))
        return mm_min <= target_mm <= mm_max
    return False


class MatchingService:
    """7-—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞–ø–ø–∏–Ω–≥–∞ –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""

    def __init__(self):
        self.db = get_supabase_client()
        self._products_cache = None
        self._mappings_cache = {}
        self._embedding_matcher = get_embedding_matcher()
        self._stats = {
            'total': 0,
            'exact_sku': 0,
            'exact_name': 0,
            'cached_mapping': 0,
            'fuzzy_sku': 0,
            'fuzzy_name': 0,
            'llm_match': 0,
            'semantic_embedding': 0,
            'not_found': 0,
            'total_confidence': 0.0,
        }

    def _load_products(self) -> list[dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ embedding –∏–Ω–¥–µ–∫—Å–∞"""
        if self._products_cache is None:
            response = self.db.table('products').select('*').execute()
            self._products_cache = response.data or []
            # –°—Ç—Ä–æ–∏–º embedding –∏–Ω–¥–µ–∫—Å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            # ENABLE_ML_MATCHING=false –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—ç–∫–æ–Ω–æ–º–∏—Ç ~500 –ú–ë RAM)
            if settings.enable_ml_matching:
                if self._products_cache and not self._embedding_matcher.is_ready:
                    try:
                        logger.info("üîß –ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–∏ –¥–ª—è semantic matching...")
                        self._embedding_matcher.build_index(self._products_cache)
                        logger.info("‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è ML matching –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return self._products_cache

    def _load_client_mappings(self, client_id: UUID | None) -> dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞–ø–ø–∏–Ω–≥–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞"""
        if client_id is None:
            return {}  # –ë–µ–∑ client_id –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        client_key = str(client_id)
        if client_key not in self._mappings_cache:
            response = self.db.table('mappings')\
                .select('client_sku, product_id, confidence, match_type')\
                .eq('client_id', str(client_id))\
                .eq('verified', True)\
                .execute()
            self._mappings_cache[client_key] = {
                normalize_sku(m['client_sku']): m
                for m in (response.data or [])
            }
        return self._mappings_cache[client_key]

    def clear_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞"""
        self._products_cache = None
        self._mappings_cache = {}

    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É matching"""
        stats = self._stats.copy()
        if stats['total'] > 0:
            stats['avg_confidence'] = round(
                stats['total_confidence'] / stats['total'], 1
            )
            stats['success_rate'] = round(
                100 * (stats['total'] - stats['not_found']) / stats['total'], 1
            )
        else:
            stats['avg_confidence'] = 0.0
            stats['success_rate'] = 0.0
        return stats

    def reset_stats(self):
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        for key in self._stats:
            self._stats[key] = 0 if isinstance(self._stats[key], int) else 0.0

    def _update_stats(self, match: MatchResult):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ match"""
        self._stats['total'] += 1
        self._stats['total_confidence'] += match.confidence
        if match.match_type in self._stats:
            self._stats[match.match_type] += 1

    def _finalize_match(self, match: MatchResult) -> MatchResult:
        """–§–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ + —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        self._update_stats(match)
        if match.product_id:
            logger.info(
                f"Matched: {match.match_type} @ {match.confidence:.0f}% "
                f"‚Üí {match.product_sku}"
            )
        else:
            logger.warning(f"Not found: {match.match_type}")
        return match

    def match_item(self, client_id: UUID | None, client_sku: str, client_name: str = None) -> MatchResult:
        """
        7-—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞–ø–ø–∏–Ω–≥–∞:
        1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞ ‚Üí 100%
        2. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è ‚Üí 95%
        3. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ ‚Üí 100%
        4. Fuzzy SKU (Levenshtein dist ‚â§ 1) ‚Üí 90%
        5. Fuzzy –Ω–∞–∑–≤–∞–Ω–∏–µ (ratio ‚â• 75) ‚Üí 80%
        6. Semantic embedding (ML) ‚Üí ‚â§75%
        7. –¢—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Üí 0%
        """
        logger.debug(f"Matching: sku={client_sku!r}, name={client_name!r}")

        products = self._load_products()
        mappings = self._load_client_mappings(client_id)

        norm_sku = normalize_sku(client_sku)
        norm_name = normalize_name(client_name) if client_name else ""

        # Level 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        if norm_sku in mappings:
            mapping = mappings[norm_sku]
            product = next((p for p in products if str(p['id']) == str(mapping['product_id'])), None)
            if product:
                return self._finalize_match(MatchResult(
                    product_id=UUID(product['id']),
                    product_sku=product['sku'],
                    product_name=product['name'],
                    confidence=settings.confidence_exact_sku,
                    match_type="cached_mapping",
                    needs_review=False,
                    pack_qty=product.get('pack_qty', 1)
                ))

        # Level 1: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞
        for product in products:
            if normalize_sku(product['sku']) == norm_sku:
                return self._finalize_match(MatchResult(
                    product_id=UUID(product['id']),
                    product_sku=product['sku'],
                    product_name=product['name'],
                    confidence=settings.confidence_exact_sku,
                    match_type="exact_sku",
                    needs_review=False,
                    pack_qty=product.get('pack_qty', 1)
                ))

        # Level 2: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        if norm_name:
            for product in products:
                if normalize_name(product['name']) == norm_name:
                    return self._finalize_match(MatchResult(
                        product_id=UUID(product['id']),
                        product_sku=product['sku'],
                        product_name=product['name'],
                        confidence=settings.confidence_exact_name,
                        match_type="exact_name",
                        needs_review=False,
                        pack_qty=product.get('pack_qty', 1)
                    ))

        # Level 4: Fuzzy SKU (Levenshtein distance ‚â§ 1)
        best_sku_match = None
        best_sku_ratio = 0
        for product in products:
            prod_norm_sku = normalize_sku(product['sku'])
            ratio = fuzz.ratio(norm_sku, prod_norm_sku)
            if ratio > best_sku_ratio and ratio >= 90:
                best_sku_ratio = ratio
                best_sku_match = product

        if best_sku_match and best_sku_ratio >= 90:
            return self._finalize_match(MatchResult(
                product_id=UUID(best_sku_match['id']),
                product_sku=best_sku_match['sku'],
                product_name=best_sku_match['name'],
                confidence=settings.confidence_fuzzy_sku * (best_sku_ratio / 100),
                match_type="fuzzy_sku",
                needs_review=best_sku_ratio < 95,
                pack_qty=best_sku_match.get('pack_qty', 1)
            ))

        # Level 5: Fuzzy –Ω–∞–∑–≤–∞–Ω–∏–µ
        if norm_name:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            client_size = extract_pipe_size(client_name or "")
            client_fitting_size = extract_fitting_size(client_name or "")
            client_thread_size = extract_thread_size(client_name or "")
            client_cat = detect_client_category(client_name or "")
            client_type = extract_product_type(client_name or "")
            client_angle = extract_angle(client_name or "")
            clamp_mm = extract_mm_from_clamp(client_name or "")
            client_wants_eco = is_eco_product(client_name or "")

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
            matches = []
            for product in products:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—á–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
                if client_size:
                    product_size = extract_pipe_size(product['name'])
                    if product_size and product_size != client_size:
                        continue

                prod_norm_name = normalize_name(product['name'])
                ratio = max(
                    fuzz.token_sort_ratio(norm_name, prod_norm_name),
                    fuzz.token_set_ratio(norm_name, prod_norm_name)
                )
                if ratio >= settings.fuzzy_threshold:
                    matches.append((product, ratio))

            if matches:
                # –í–ê–ñ–ù–û: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã –∫–æ –í–°–ï–ú matches,
                # –ø–æ—Ç–æ–º –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏—Ö. –ò–Ω–∞—á–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø –º–æ–∂–µ—Ç –∏–º–µ—Ç—å
                # –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π score –∏ –≤—ã—Ç–µ—Å–Ω–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.
                client_thread = extract_thread_type(client_name or "")

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É —Ç–æ–≤–∞—Ä–∞ - –ø—Ä–∏–º–µ–Ω—è–µ–º –∫–æ –≤—Å–µ–º
                if client_type:
                    type_filtered = [m for m in matches
                                     if extract_product_type(m[0]['name']) == client_type]
                    if type_filtered:
                        matches = type_filtered

                # –§–∏–ª—å—Ç—Ä –ø–æ —É–≥–ª—É - –ø—Ä–∏–º–µ–Ω—è–µ–º –∫–æ –≤—Å–µ–º (—Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π 90¬∞ ‚Üí 87¬∞)
                if client_angle:
                    normalized_angle = normalize_angle(client_angle)
                    if normalized_angle:  # None = —É–≥–æ–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (30¬∞ –≤ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
                        angle_filtered = [m for m in matches
                                          if extract_angle(m[0]['name']) == normalized_angle]
                        if angle_filtered:
                            matches = angle_filtered

                # –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ - –ø—Ä–∏–º–µ–Ω—è–µ–º –∫–æ –í–°–ï–ú matches (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –º—É—Ñ—Ç)
                # –ò–Ω–∞—á–µ 604 (—Ä–∏—Ñ–ª–µ–Ω—ã–µ) –º–æ–≥—É—Ç –∏–º–µ—Ç—å –≤—ã—à–µ score —á–µ–º 202 (–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è)
                # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞ - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'sewer' (—Å–µ—Ä–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è)
                effective_cat = client_cat or 'sewer'
                cat_filtered = filter_by_category(matches, effective_cat)
                if cat_filtered:
                    matches = cat_filtered

                # –¢–µ–ø–µ—Ä—å —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä—ë–º top
                matches.sort(key=lambda x: x[1], reverse=True)
                best_ratio = matches[0][1]
                top_matches = [m for m in matches if m[1] >= best_ratio - 2]

                # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ñ–∏–ª—å—Ç—Ä—ã
                top_matches = filter_by_thread(top_matches, client_thread)

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º —Ñ–∏—Ç–∏–Ω–≥–æ–≤ (110/50 vs 110/110)
                top_matches = filter_by_fitting_size(top_matches, client_fitting_size)

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ä–µ–∑—å–±—ã (32√ó1" –¥–ª—è –º—É—Ñ—Ç –ù–†/–í–†)
                top_matches = filter_by_thread_size(top_matches, client_thread_size)

                # –•–æ–º—É—Ç—ã - —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –º–º
                if clamp_mm and len(top_matches) > 1:
                    fitting = [m for m in top_matches
                               if clamp_fits_mm(m[0]['name'], clamp_mm)]
                    if fitting:
                        top_matches = fitting

                # –ï—Å–ª–∏ –ù–ï –≠–ö–û - –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç
                if not client_wants_eco and len(top_matches) > 1:
                    non_eco = [m for m in top_matches
                               if not is_eco_product(m[0]['name'])]
                    if non_eco:
                        top_matches = non_eco

                best_match, best_ratio = top_matches[0]
                conf = settings.confidence_fuzzy_name * (best_ratio / 100)
                if len(matches) > 1 and not client_wants_eco:
                    conf = min(conf + 5, 95.0)

                # –ï—Å–ª–∏ confidence –Ω–∏–∑–∫–∏–π (<75%) - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á–µ—Ä–µ–∑ LLM
                if conf < 75:
                    llm = get_llm_matcher()
                    if llm:
                        if not llm.is_ready:
                            llm.set_products(products)
                        llm_result = llm.match(client_name)
                        if llm_result and llm_result.get("sku"):
                            llm_conf = float(llm_result.get("confidence", 0))
                            if llm_conf > conf:
                                llm_product = next(
                                    (p for p in products
                                     if p["sku"] == llm_result["sku"]),
                                    None
                                )
                                if llm_product:
                                    return self._finalize_match(MatchResult(
                                        product_id=UUID(llm_product['id']),
                                        product_sku=llm_product['sku'],
                                        product_name=llm_product['name'],
                                        confidence=llm_conf,
                                        match_type="llm_match",
                                        needs_review=llm_conf < 80,
                                        pack_qty=llm_product.get('pack_qty', 1)
                                    ))

                return self._finalize_match(MatchResult(
                    product_id=UUID(best_match['id']),
                    product_sku=best_match['sku'],
                    product_name=best_match['name'],
                    confidence=conf,
                    match_type="fuzzy_name",
                    needs_review=conf < settings.min_confidence_auto,
                    pack_qty=best_match.get('pack_qty', 1)
                ))

        # Level 7: LLM matching —á–µ—Ä–µ–∑ OpenRouter API
        llm = get_llm_matcher()
        if llm and client_name:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—Ç–∞–ª–æ–≥ –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
            if not llm.is_ready:
                llm.set_products(products)

            result = llm.match(client_name)
            if result and result.get("sku"):
                # –ò—â–µ–º —Ç–æ–≤–∞—Ä –ø–æ SKU –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
                product = next(
                    (p for p in products if p["sku"] == result["sku"]),
                    None
                )
                if product:
                    # Post-validation: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ç—Ä—É–±—ã
                    client_size = extract_pipe_size(client_name)
                    if client_size:
                        product_size = extract_pipe_size(product['name'])
                        if product_size and product_size != client_size:
                            # –†–∞–∑–º–µ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç - –∏—â–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–æ–≤–∞—Ä
                            logger.debug(f"LLM size mismatch: {client_size} vs {product_size}")
                            product = None  # –û—Ç–∫–ª–æ–Ω—è–µ–º LLM —Ä–µ–∑—É–ª—å—Ç–∞—Ç

                if product:
                    conf = float(result.get("confidence", 70))
                    return self._finalize_match(MatchResult(
                        product_id=UUID(product['id']),
                        product_sku=product['sku'],
                        product_name=product['name'],
                        confidence=conf,
                        match_type="llm_match",
                        needs_review=conf < 80,
                        pack_qty=product.get('pack_qty', 1)
                    ))

        # Fallback: Semantic embedding (–µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
        if self._embedding_matcher.is_ready and client_name:
            results = self._embedding_matcher.search(
                client_name, top_k=20, min_score=0.4
            )
            if results:
                client_cat = detect_client_category(client_name)
                client_type = extract_product_type(client_name)
                client_angle = extract_angle(client_name)
                client_thread = extract_thread_type(client_name)
                client_fitting_size = extract_fitting_size(client_name)
                client_thread_size = extract_thread_size(client_name)

                filtered = filter_by_product_type(results, client_type)
                filtered = filter_by_angle(filtered, client_angle)
                filtered = filter_by_thread(filtered, client_thread)
                filtered = filter_by_category(filtered, client_cat)
                filtered = filter_by_fitting_size(filtered, client_fitting_size)
                filtered = filter_by_thread_size(filtered, client_thread_size)

                if filtered:
                    product, score = filtered[0]
                    conf = score * 100 * 0.75
                    return self._finalize_match(MatchResult(
                        product_id=UUID(product['id']),
                        product_sku=product['sku'],
                        product_name=product['name'],
                        confidence=conf,
                        match_type="semantic_embedding",
                        needs_review=True,
                        pack_qty=product.get('pack_qty', 1)
                    ))

        # Level 8: –ù–µ –Ω–∞–π–¥–µ–Ω–æ - —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        return self._finalize_match(MatchResult(
            product_id=None,
            product_sku=None,
            product_name=None,
            confidence=0.0,
            match_type="not_found",
            needs_review=True
        ))

    def match_order_items(self, client_id: UUID, items: list[dict],
                          auto_save: bool = True) -> list[dict]:
        """
        –ú–∞–ø–ø–∏–Ω–≥ –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π –∑–∞–∫–∞–∑–∞.

        Args:
            client_id: ID –∫–ª–∏–µ–Ω—Ç–∞
            items: –°–ø–∏—Å–æ–∫ –ø–æ–∑–∏—Ü–∏–π –∑–∞–∫–∞–∑–∞
            auto_save: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–∞–ø–ø–∏–Ω–≥–∏ —Å –≤—ã—Å–æ–∫–∏–º confidence
        """
        results = []
        for item in items:
            client_sku = item.get('client_sku', '')
            match = self.match_item(
                client_id=client_id,
                client_sku=client_sku,
                client_name=item.get('client_name', '')
            )

            # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω—ã—Ö –º–∞–ø–ø–∏–Ω–≥–æ–≤
            auto_saved = False
            if auto_save and client_sku:
                auto_saved = self.auto_save_high_confidence(client_id, client_sku, match)

            results.append({
                **item,
                'match': match.model_dump(),
                'auto_saved': auto_saved
            })
        return results

    def save_mapping(self, client_id: UUID, client_sku: str, product_id: UUID,
                     confidence: float, match_type: str, verified: bool = False):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –≤ –ë–î"""
        data = {
            'client_id': str(client_id),
            'client_sku': client_sku,
            'product_id': str(product_id),
            'confidence': confidence,
            'match_type': match_type,
            'verified': verified
        }

        # Upsert - –æ–±–Ω–æ–≤–ª—è–µ–º –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self.db.table('mappings').upsert(
            data,
            on_conflict='client_id,client_sku'
        ).execute()

        # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à
        client_key = str(client_id)
        if client_key in self._mappings_cache:
            del self._mappings_cache[client_key]

    def auto_save_high_confidence(self, client_id: UUID, client_sku: str,
                                   match: MatchResult) -> bool:
        """
        –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º confidence (‚â•95%).
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞–∫ unverified - —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è.

        Returns:
            True –µ—Å–ª–∏ –º–∞–ø–ø–∏–Ω–≥ –±—ã–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω
        """
        if (match.confidence >= settings.confidence_exact_name and
            match.product_id is not None and
            match.match_type in ("exact_sku", "exact_name", "cached_mapping")):
            try:
                self.save_mapping(
                    client_id=client_id,
                    client_sku=client_sku,
                    product_id=match.product_id,
                    confidence=match.confidence,
                    match_type=match.match_type,
                    verified=False  # –¢—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                )
                return True
            except Exception:
                pass
        return False
