import re
import logging
from threading import Lock
from uuid import UUID
from fuzzywuzzy import fuzz
from backend.models.database import get_supabase_client
from backend.utils.normalizers import (
    normalize_sku, normalize_name, extract_pipe_size, extract_fitting_size,
    extract_thread_size, is_coupling_detachable, is_reducer
)
from backend.config import settings
from backend.models.schemas import MatchResult
from backend.services.embeddings import get_embedding_matcher
from backend.services.llm_matcher import get_llm_matcher

logger = logging.getLogger(__name__)


def detect_client_category(client_name: str) -> str | None:
    """
    –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞.
    Returns: 'pert', 'pnd', 'prestige', 'outdoor', 'ppr', 'sewer', –∏–ª–∏ None
    """
    name = client_name.lower()

    is_sewer = any(x in name for x in ['–∫–∞–Ω', '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü', '—Å–∞–Ω—Ç–µ—Ö'])
    is_gray = '—Å–µ—Ä' in name  # —Å–µ—Ä—ã–π/—Å–µ—Ä–∞—è = –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è

    # PERT (–ø–æ–ª–∏—ç—Ç–∏–ª–µ–Ω —Ç–µ—Ä–º–æ—Å—Ç–æ–π–∫–∏–π) - –∞—Ä—Ç–∏–∫—É–ª—ã 501...
    # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è—Ç—å –î–û –ü–ù–î –∏ –ü–ü–†!
    if any(x in name for x in ['pert', 'pe-rt', '—Ç–µ—Ä–º–æ—Å—Ç–æ–π–∫']):
        return 'pert'

    # –ü–ù–î (–ø–æ–ª–∏—ç—Ç–∏–ª–µ–Ω, –∫–æ–º–ø—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ —Ñ–∏—Ç–∏–Ω–≥–∏) - –∞—Ä—Ç–∏–∫—É–ª—ã 704...
    # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è—Ç—å –î–û –ü–ü–†, —Ç.–∫. –æ–±–∞ –¥–ª—è –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–∞!
    if any(x in name for x in ['–ø–Ω–¥', 'hdpe', '–∫–æ–º–ø—Ä–µ—Å—Å', '—Ü–∞–Ω–≥']):
        return 'pnd'

    # –ú–∞–ª–æ—à—É–º–Ω–∞—è/Prestige = –±–µ–ª–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è (403)
    if any(x in name for x in ['–º–∞–ª–æ—à—É–º', 'prestige']):
        return 'prestige'
    # –ë–µ–ª–∞—è + –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è = —Ç–æ–∂–µ Prestige
    if is_sewer and '–±–µ–ª' in name:
        return 'prestige'

    # –ù–∞—Ä—É–∂–Ω–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è = —Ä—ã–∂–∞—è (303)
    if any(x in name for x in ['–Ω–∞—Ä –∫–∞–Ω', '–Ω–∞—Ä.–∫–∞–Ω', '–Ω–∞—Ä—É–∂–Ω', '—Ä—ã–∂']):
        return 'outdoor'

    # –°–µ—Ä–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è - –†–ê–ù–¨–®–ï –ü–ü–†! (202)
    # –ü–ü —Å–µ—Ä–∞—è = –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è, –Ω–µ –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥
    if is_gray or is_sewer:
        return 'sewer'

    # –ü–ü–† (–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥/–æ—Ç–æ–ø–ª–µ–Ω–∏–µ) - –±–µ–ª—ã–π, –Ω–æ –ù–ï –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ù–ï —Å–µ—Ä—ã–π
    # "–ü–ü" = –ø–æ–ª–∏–ø—Ä–æ–ø–∏–ª–µ–Ω = –ü–ü–†
    if any(x in name for x in ['–ø–ø—Ä', 'ppr', '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥', '–æ—Ç–æ–ø–ª–µ–Ω', ' –ø–ø ', '–ø–ø ']):
        return 'ppr'
    # –ê—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç—Ä—É–±–∞ = –ü–ü–† (–Ω–µ –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è!)
    if any(x in name for x in ['–∞—Ä–º–∏—Ä', '–∞—Ä–º.', '–∞—Ä–º ']):
        return 'ppr'
    # –ü–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫–∏ –í–ù/–ù–† = —Ç–æ–ª—å–∫–æ –ü–ü–† (–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥)
    if any(x in name for x in ['–≤–Ω/–Ω—Ä', '–≤–Ω –Ω—Ä', '–ø–Ω/–Ω—Ä']):
        return 'ppr'
    if '–±–µ–ª' in name and not is_sewer:
        return 'ppr'

    return None  # –ù–µ —É–∫–∞–∑–∞–Ω–æ - –¥–µ—Ñ–æ–ª—Ç: –æ–±—ã—á–Ω–∞—è —Å–µ—Ä–∞—è –∫–∞–Ω.


def extract_product_type(name: str) -> str | None:
    """
    –ò–∑–≤–ª–µ—á—å —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è.
    Returns: '—Ç—Ä—É–±–∞', '–æ—Ç–≤–æ–¥', '—Ç—Ä–æ–π–Ω–∏–∫', '–º—É—Ñ—Ç–∞', '–∑–∞–≥–ª—É—à–∫–∞', '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫',
             '—Ä–µ–≤–∏–∑–∏—è', '–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω–∞', '–ø–∞—Ç—Ä—É–±–æ–∫', '—Ö–æ–º—É—Ç', '–∫—Ä–∞–Ω', '—Ñ–∏–ª—å—Ç—Ä',
             '–∫–ª–∞–ø–∞–Ω', '—Å–∏—Ñ–æ–Ω' –∏–ª–∏ None
    """
    name_lower = name.lower()

    # –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω - –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–µ—Ä–≤—ã–µ
    # –í–ê–ñ–ù–û: "—Ä–µ–¥" –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –î–û "–º—É—Ñ—Ç", —Ç.–∫. "–ú—É—Ñ—Ç–∞ —Ä–µ–¥." = "–ú—É—Ñ—Ç–∞ –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫"
    types = [
        ('–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω', '–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω–∞'),
        ('—Ç—Ä–æ–π–Ω–∏–∫', '—Ç—Ä–æ–π–Ω–∏–∫'),
        ('–ø–µ—Ä–µ—Ö–æ–¥', '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫'),
        ('—Ä–µ–¥', '–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫'),  # "—Ä–µ–¥." = —Ä–µ–¥—É–∫—Ü–∏–æ–Ω–Ω—ã–π = –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫
        ('—Ä–∞–∑—ä–µ–º–Ω', '–º—É—Ñ—Ç–∞'),  # –º—É—Ñ—Ç–∞ —Ä–∞–∑—ä–µ–º–Ω–∞—è = –∞–º–µ—Ä–∏–∫–∞–Ω–∫–∞
        ('–æ—Ç–≤–æ–¥', '–æ—Ç–≤–æ–¥'),
        ('–∫–æ–ª–µ–Ω–æ', '–æ—Ç–≤–æ–¥'),
        ('—É–≥–æ–ª', '–æ—Ç–≤–æ–¥'),
        ('–º—É—Ñ—Ç', '–º—É—Ñ—Ç–∞'),
        ('–∑–∞–≥–ª—É—à', '–∑–∞–≥–ª—É—à–∫–∞'),
        ('—Ä–µ–≤–∏–∑–∏', '—Ä–µ–≤–∏–∑–∏—è'),
        ('–ø–∞—Ç—Ä—É–±', '–ø–∞—Ç—Ä—É–±–æ–∫'),
        ('–æ–ø–æ—Ä', '–∫–ª–∏–ø—Å–∞'),  # –æ–ø–æ—Ä–∞ –¥–ª—è —Ç—Ä—É–± = –∫–ª–∏–ø—Å–∞
        ('–∫–ª–∏–ø—Å', '–∫–ª–∏–ø—Å–∞'),
        ('—Ç—Ä—É–±', '—Ç—Ä—É–±–∞'),
        ('—Ö–æ–º—É—Ç', '—Ö–æ–º—É—Ç'),
        ('–∫—Ä–∞–Ω', '–∫—Ä–∞–Ω'),
        ('—Ñ–∏–ª—å—Ç—Ä', '—Ñ–∏–ª—å—Ç—Ä'),
        ('–∫–ª–∞–ø–∞–Ω', '–∫–ª–∞–ø–∞–Ω'),
        ('—Å–∏—Ñ–æ–Ω', '—Å–∏—Ñ–æ–Ω'),
    ]

    for marker, ptype in types:
        if marker in name_lower:
            return ptype
    return None


def extract_angle(name: str) -> int | None:
    """–ò–∑–≤–ª–µ—á—å —É–≥–æ–ª –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è (15¬∞, 30¬∞, 45¬∞, 67¬∞, 87¬∞, 90¬∞)"""
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –≤—Å–µ —É–≥–ª—ã, –¥–∞–∂–µ –µ—Å–ª–∏ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –∏—Ö –Ω–µ—Ç
    m = re.search(r'\b(15|30|45|67|87|90)\s*[¬∞–≥—Ä–∞–¥—É—Å]?', name.lower())
    if m:
        return int(m.group(1))
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: /45, /90
    m = re.search(r'/\s*(15|30|45|67|87|90)\b', name.lower())
    if m:
        return int(m.group(1))
    return None


def normalize_angle(angle: int | None) -> int | None:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —É–≥–æ–ª –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –∫–∞—Ç–∞–ª–æ–≥—É Jakko.
    90¬∞ ‚Üí 87¬∞ (–≤ –∫–∞—Ç–∞–ª–æ–≥–µ Jakko –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 87¬∞ –≤–º–µ—Å—Ç–æ 90¬∞)
    """
    if angle is None:
        return None
    if angle == 90:
        return 87  # Jakko convention: 87¬∞ –≤–º–µ—Å—Ç–æ 90¬∞
    return angle


def filter_by_category(matches: list, client_cat: str | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
    matches: —Å–ø–∏—Å–æ–∫ (product, score) –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ product dicts
    """
    if not matches:
        return matches

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç: (product, score) –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ product
    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = None
    if client_cat == 'pert':
        # PERT - –∞—Ä—Ç–∏–∫—É–ª—ã 501xxx (–ø–æ–ª–∏—ç—Ç–∏–ª–µ–Ω —Ç–µ—Ä–º–æ—Å—Ç–æ–π–∫–∏–π)
        filtered = [m for m in matches
                    if get_product(m).get('sku', '').startswith('501')
                    or 'pert' in get_product(m)['name'].lower()]
    elif client_cat == 'pnd':
        # –ü–ù–î - –∞—Ä—Ç–∏–∫—É–ª—ã 704xxx (–∫–æ–º–ø—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ —Ñ–∏—Ç–∏–Ω–≥–∏)
        filtered = [m for m in matches
                    if get_product(m).get('sku', '').startswith('704')
                    or '–∫–æ–º–ø—Ä–µ—Å—Å' in get_product(m)['name'].lower()]
    elif client_cat == 'prestige':
        filtered = [m for m in matches
                    if '–º–∞–ª–æ—à—É–º' in get_product(m).get('category', '').lower()
                    or 'prestige' in get_product(m)['name'].lower()]
    elif client_cat == 'outdoor':
        # –ù–∞—Ä—É–∂–Ω–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è: 303xxx + —Ä–∏—Ñ–ª–µ–Ω—ã–µ 604xxx
        filtered = [m for m in matches
                    if get_product(m).get('sku', '').startswith(('303', '604'))
                    or '–Ω–∞—Ä—É–∂–Ω' in get_product(m).get('category', '').lower()
                    or '–Ω–∞—Ä.–∫–∞–Ω' in get_product(m)['name'].lower()
                    or '—Ä–∏—Ñ–ª–µ–Ω' in get_product(m)['name'].lower()]
    elif client_cat == 'ppr':
        filtered = [m for m in matches
                    if '–ø–ø—Ä' in get_product(m).get('category', '').lower()
                    or '–ø–ø—Ä' in get_product(m)['name'].lower()]
    elif client_cat == 'sewer':
        # –°–ï–†–ê–Ø –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è (202) - –ù–ï —Ä–∏—Ñ–ª–µ–Ω—ã–µ, –ù–ï Prestige, –ù–ï –Ω–∞—Ä—É–∂–Ω–∞—è
        # –°—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö
        return [m for m in matches
                if get_product(m).get('sku', '').startswith('202')
                or ('—Å–µ—Ä—ã–π' in get_product(m)['name'].lower()
                    and '—Ä–∏—Ñ–ª–µ–Ω' not in get_product(m)['name'].lower())]
    else:
        # –î–µ—Ñ–æ–ª—Ç: –æ–±—ã—á–Ω–∞—è –°–ï–†–ê–Ø –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è (202)
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: SKU –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 202 (—Å–µ—Ä–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è)
        sku_202 = [m for m in matches
                   if get_product(m).get('sku', '').startswith('202')]
        if sku_202:
            return sku_202

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –ö–∞—Ç–µ–≥–æ—Ä–∏—è "–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è" (–Ω–µ –º–∞–ª–æ—à—É–º/–Ω–∞—Ä—É–∂–Ω–∞—è)
        filtered = [m for m in matches
                    if ('–∫–∞–Ω–∞–ª–∏–∑–∞—Ü' in get_product(m).get('category', '').lower()
                        and '–º–∞–ª–æ—à—É–º' not in get_product(m).get('category', '').lower()
                        and '–Ω–∞—Ä—É–∂–Ω' not in get_product(m).get('category', '').lower())
                    or '—Å–µ—Ä—ã–π' in get_product(m)['name'].lower()]

    return filtered if filtered else matches


def filter_by_product_type(matches: list, client_type: str | None) -> list:
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ç–∏–ø—É —Ç–æ–≤–∞—Ä–∞ (–æ—Ç–≤–æ–¥, –º—É—Ñ—Ç–∞, –∑–∞–≥–ª—É—à–∫–∞ –∏ —Ç.–¥.)"""
    if not matches or not client_type or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if extract_product_type(get_product(m)['name']) == client_type]

    return filtered if filtered else matches


def filter_by_detachable(matches: list, client_is_detachable: bool) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ç–∏–ø—É –º—É—Ñ—Ç—ã: —Ä–∞–∑—ä–µ–º–Ω–∞—è (–∞–º–µ—Ä–∏–∫–∞–Ω–∫–∞) vs –æ–±—ã—á–Ω–∞—è.

    –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç "—Ä–∞–∑—ä–µ–º–Ω—É—é" –∏–ª–∏ "–∞–º–µ—Ä–∏–∫–∞–Ω–∫—É", –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–∑—ä–µ–º–Ω—ã–µ.
    –ï—Å–ª–∏ –Ω–µ—Ç - –Ω–µ —Ñ–∏–ª—å—Ç—Ä—É–µ–º (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ).
    """
    if not matches or not client_is_detachable or len(matches) <= 1:
        return matches

    from backend.utils.normalizers import is_coupling_detachable

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if is_coupling_detachable(get_product(m)['name'])]

    return filtered if filtered else matches


def filter_by_reducer(matches: list, client_is_reducer: bool) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫–∞ (—Ä–∞–∑–Ω—ã–µ –¥–∏–∞–º–µ—Ç—Ä—ã).

    –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫/–ø–µ—Ä–µ—Ö–æ–¥–Ω—É—é", –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫–∏.
    """
    if not matches or not client_is_reducer or len(matches) <= 1:
        return matches

    from backend.utils.normalizers import is_reducer

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if is_reducer(get_product(m)['name'])]

    return filtered if filtered else matches


def filter_by_angle(matches: list, client_angle: int | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —É–≥–ª—É (15¬∞, 30¬∞, 45¬∞, 67¬∞, 87¬∞, 90¬∞).
    90¬∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç—Å—è –≤ 87¬∞ (Jakko convention).
    """
    if not matches or not client_angle or len(matches) <= 1:
        return matches

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —É–≥–æ–ª –∫–ª–∏–µ–Ω—Ç–∞ (90¬∞ ‚Üí 87¬∞)
    normalized_angle = normalize_angle(client_angle)

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if extract_angle(get_product(m)['name']) == normalized_angle]

    return filtered if filtered else matches


def extract_thread_type(name: str) -> str | None:
    """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø —Ä–µ–∑—å–±—ã: '–≤–Ω' (–≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è) –∏–ª–∏ '–Ω–∞—Ä' (–Ω–∞—Ä—É–∂–Ω–∞—è)"""
    name_lower = name.lower()
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Ä–µ–∑—å–±—ã: –≤/—Ä, –≤–Ω.—Ä–µ–∑, –≤–Ω. —Ä–µ–∑, –≤–Ω—É—Ç—Ä, (–≤—Ä), –≤—Ä)
    if any(x in name_lower for x in ['–≤/—Ä', '–≤–Ω.—Ä–µ–∑', '–≤–Ω. —Ä–µ–∑', '–≤–Ω —Ä–µ–∑', '–≤–Ω—É—Ç—Ä', '(–≤—Ä)', '–≤—Ä)', ' –≤—Ä ']):
        return '–≤–Ω'
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞—Ä—É–∂–Ω–æ–π —Ä–µ–∑—å–±—ã: –Ω/—Ä, –Ω–∞—Ä.—Ä–µ–∑, –Ω–∞—Ä. —Ä–µ–∑, –Ω–∞—Ä—É–∂, (–Ω—Ä), –Ω—Ä)
    if any(x in name_lower for x in ['–Ω/—Ä', '–Ω–∞—Ä.—Ä–µ–∑', '–Ω–∞—Ä. —Ä–µ–∑', '–Ω–∞—Ä —Ä–µ–∑', '–Ω–∞—Ä—É–∂', '(–Ω—Ä)', '–Ω—Ä)', ' –Ω—Ä ']):
        return '–Ω–∞—Ä'
    return None


def filter_by_thread(matches: list, client_thread: str | None) -> list:
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ç–∏–ø—É —Ä–µ–∑—å–±—ã (–≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è/–Ω–∞—Ä—É–∂–Ω–∞—è)"""
    if not matches or not client_thread or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = [m for m in matches
                if extract_thread_type(get_product(m)['name']) == client_thread]

    return filtered if filtered else matches


def filter_by_fitting_size(matches: list, client_size: tuple | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º —Ñ–∏—Ç–∏–Ω–≥–∞ (110/50, 110/110 –∏ —Ç.–¥.)

    –õ–æ–≥–∏–∫–∞:
    - –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 2 —Ä–∞–∑–º–µ—Ä–∞ (110/50) - –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    - –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 1 —Ä–∞–∑–º–µ—Ä (110) - –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã (110-110),
      –µ—Å–ª–∏ –Ω–µ—Ç - —Ç–æ–≥–¥–∞ –∏—â–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É
    """
    if not matches or not client_size or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 2+ —Ä–∞–∑–º–µ—Ä–∞ - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if len(client_size) >= 2:
        # –î–ª—è 3 —Ä–∞–∑–º–µ—Ä–æ–≤ (—Ç—Ä–æ–π–Ω–∏–∫ –ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫ 40-25-40) - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if len(client_size) == 3:
            filtered = [m for m in matches
                        if extract_fitting_size(get_product(m)['name']) == client_size]
            if filtered:
                return filtered
            # Fallback: –¥–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫—É –∫—Ä–∞–π–Ω–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
            # 40-25-40 == 40-25-40 (—Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Ç–æ—á–Ω–æ)
            filtered = [m for m in matches
                        if (ps := extract_fitting_size(get_product(m)['name']))
                        and len(ps) == 3
                        and ps[1] == client_size[1]  # —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ç–æ—á–Ω–æ
                        and set([ps[0], ps[2]]) == set([client_size[0], client_size[2]])]
            return filtered if filtered else matches

        # –î–ª—è 2 —Ä–∞–∑–º–µ—Ä–æ–≤ - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, —Å fallback –ø–æ –ø–µ—Ä–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É
        filtered = [m for m in matches
                    if extract_fitting_size(get_product(m)['name']) == client_size]
        if filtered:
            return filtered
        # Fallback: –∏—â–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É (50-32 ‚Üí 50-50, 50-40)
        first_size = client_size[0]
        filtered = [m for m in matches
                    if (ps := extract_fitting_size(get_product(m)['name']))
                    and ps[0] == first_size]
        return filtered if filtered else matches

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∫–∞–∑–∞–ª 1 —Ä–∞–∑–º–µ—Ä (110) - –∏—â–µ–º —Ç–æ–≤–∞—Ä—ã —Å –û–î–ù–ò–ú —Ä–∞–∑–º–µ—Ä–æ–º –∏–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏
    single_size = client_size[0]

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –¢–æ–≤–∞—Ä—ã —Å –æ–¥–Ω–∏–º —Ä–∞–∑–º–µ—Ä–æ–º (–ø—Ä–æ—Å—Ç–æ 110, –±–µ–∑ –≤—Ç–æ—Ä–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞)
    # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –æ—Ç–≤–æ–¥–æ–≤: "–æ—Ç–≤–æ–¥ 110" != "–æ—Ç–≤–æ–¥ 110-50"
    single_only = [m for m in matches
                   if (ps := extract_fitting_size(get_product(m)['name']))
                   and len(ps) == 1 and ps[0] == single_size]
    if single_only:
        return single_only

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã (110-110, 50-50) - –ø—Ä—è–º–æ–π —Ç—Ä–æ–π–Ω–∏–∫/–º—É—Ñ—Ç–∞
    same_size = [m for m in matches
                 if extract_fitting_size(get_product(m)['name']) == (single_size, single_size)]
    if same_size:
        return same_size

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –ü–µ—Ä–≤—ã–π —Ä–∞–∑–º–µ—Ä —Å–æ–≤–ø–∞–¥–∞–µ—Ç (110-50, 110-110) - fallback
    first_match = [m for m in matches
                   if (ps := extract_fitting_size(get_product(m)['name']))
                   and ps[0] == single_size]
    return first_match if first_match else matches


def filter_by_thread_size(matches: list, client_thread: tuple | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ä–µ–∑—å–±—ã (32√ó1", 25√ó3/4" –∏ —Ç.–¥.)

    client_thread: (–º–º, –¥—é–π–º—ã) - –Ω–∞–ø—Ä–∏–º–µ—Ä (32, "1")
    """
    if not matches or not client_thread or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    mm, inches = client_thread
    # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã —Å —Ç–∞–∫–∏–º –∂–µ —Ä–∞–∑–º–µ—Ä–æ–º —Ä–µ–∑—å–±—ã –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
    # –§–æ—Ä–º–∞—Ç—ã –∫–∞—Ç–∞–ª–æ–≥–∞: "32x1"", "32√ó1"", "32*1""
    filtered = []
    for m in matches:
        name = get_product(m)['name'].lower()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Å —Ä–µ–∑—å–±–æ–π
        if (f'{mm}x{inches}"' in name or
            f'{mm}√ó{inches}"' in name or
            f'{mm}*{inches}"' in name or
            f'{mm}-{inches}"' in name):
            filtered.append(m)

    return filtered if filtered else matches


def filter_by_clamp_size(matches: list, client_mm: int | None) -> list:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç —Ö–æ–º—É—Ç—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É –≤ –º–º.

    client_mm: —Ä–∞–∑–º–µ—Ä –≤ –º–º (50, 110 –∏ —Ç.–¥.)
    –•–æ–º—É—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç –µ—Å–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω (87-92) –≤–∫–ª—é—á–∞–µ—Ç client_mm
    """
    if not matches or not client_mm or len(matches) <= 1:
        return matches

    is_tuple = isinstance(matches[0], tuple)

    def get_product(m):
        return m[0] if is_tuple else m

    filtered = []
    for m in matches:
        name = get_product(m)['name']
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —Ö–æ–º—É—Ç –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É
        if clamp_fits_mm(name, client_mm):
            filtered.append(m)

    return filtered if filtered else matches


def is_eco_product(name: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–æ–≤–∞—Ä –≠–ö–û (—ç–∫–æ–Ω–æ–º) –≤–µ—Ä—Å–∏–µ–π.

    –¢–æ–ª—â–∏–Ω—ã —Å—Ç–µ–Ω–æ–∫:
    - (1.8) –¥–ª—è 32/40/50 –º–º = —Å—Ç–∞–Ω–¥–∞—Ä—Ç (–Ω–µ –≠–ö–û)
    - (2.2) –¥–ª—è 110 –º–º = –≠–ö–û (—Ç–æ–Ω–∫–æ—Å—Ç–µ–Ω–Ω–∞—è)
    - (2.7) –¥–ª—è 110 –º–º = —Å—Ç–∞–Ω–¥–∞—Ä—Ç
    """
    name_lower = name.lower()
    # (1.8) - —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è —Ç—Ä—É–± 32/40/50, —è–≤–Ω–æ –Ω–µ –≠–ö–û
    if '(1.8)' in name_lower:
        return False
    return '—ç–∫–æ' in name_lower or 'eko' in name_lower or '(2.2)' in name_lower


def extract_mm_from_clamp(client_name: str) -> int | None:
    """–ò–∑–≤–ª–µ—á—å —Ä–∞–∑–º–µ—Ä –≤ –º–º –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —Ö–æ–º—É—Ç–∞"""
    name = client_name.lower()
    if '—Ö–æ–º—É—Ç' not in name:
        return None
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
    # - "—Ö–æ–º—É—Ç 110"
    # - "—Ö–æ–º—É—Ç –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ 110"
    # - "—Ö–æ–º—É—Ç –¥–ª—è —Ç—Ä—É–±—ã 110"
    # - "—Ö–æ–º—É—Ç 110–º–º"
    # - "—Ö–æ–º—É—Ç ‚àÖ110" –∏–ª–∏ "—Ö–æ–º—É—Ç d110"
    patterns = [
        r'\b—Ö–æ–º—É—Ç\s+(?:–≤\s+–∫–æ–º–ø–ª–µ–∫—Ç–µ\s+)?(\d+)',
        r'\b—Ö–æ–º—É—Ç\s+(?:–¥–ª—è\s+)?(?:—Ç—Ä—É–±\w*\s+)?(\d+)',
        r'\b—Ö–æ–º—É—Ç\s*[‚àÖd–¥]?\s*(\d+)',
    ]
    for pattern in patterns:
        m = re.search(pattern, name)
        if m:
            mm = int(m.group(1))
            # –í–∞–ª–∏–¥–∞—Ü–∏—è: —Ä–∞–∑–º–µ—Ä—ã —Ö–æ–º—É—Ç–æ–≤ 15-200–º–º
            if 15 <= mm <= 200:
                return mm
    return None


def normalize_equal_sizes(size: tuple) -> tuple:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã: (25, 25) ‚Üí (25,), (20, 20, 20) ‚Üí (20,)

    –î–ª—è –ü–ù–î –∫–æ–º–ø—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö —Ñ–∏—Ç–∏–Ω–≥–æ–≤:
    - "–û—Ç–≤–æ–¥ 25-25" –≤ –∑–∞–ø—Ä–æ—Å–µ = "–û—Ç–≤–æ–¥ 25" –≤ –∫–∞—Ç–∞–ª–æ–≥–µ
    - "–¢—Ä–æ–π–Ω–∏–∫ 20-20-20" = "–¢—Ä–æ–π–Ω–∏–∫ 20"

    –ù–ï –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã (–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫–∏):
    - (25, 20) –æ—Å—Ç–∞—ë—Ç—Å—è (25, 20)
    - (32, 25, 32) –æ—Å—Ç–∞—ë—Ç—Å—è (32, 25, 32)
    """
    if not size:
        return size
    if len(size) >= 2 and len(set(size)) == 1:
        return (size[0],)  # –í—Å–µ —Ä–∞–∑–º–µ—Ä—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã
    return size


def clamp_fits_mm(product_name: str, target_mm: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —Ö–æ–º—É—Ç –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –º–º"""
    # –§–æ—Ä–º–∞—Ç: (107-115) –∏–ª–∏ (87-92)
    m = re.search(r'\((\d+)-(\d+)\)', product_name)
    if m:
        mm_min, mm_max = int(m.group(1)), int(m.group(2))
        return mm_min <= target_mm <= mm_max
    return False


class MatchingService:
    """7-—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞–ø–ø–∏–Ω–≥–∞ –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""

    def __init__(self):
        self.db = get_supabase_client()
        self._products_cache = None
        self._mappings_cache = {}
        self._mappings_lock = Lock()  # Thread safety –¥–ª—è _mappings_cache
        self._embedding_matcher = get_embedding_matcher()
        self._stats = {
            'total': 0,
            'exact_sku': 0,
            'exact_name': 0,
            'cached_mapping': 0,
            'fuzzy_sku': 0,
            'fuzzy_name': 0,  # —Ç–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç pgvector + fuzzy hybrid
            'llm_match': 0,
            'not_found': 0,
            'total_confidence': 0.0,
        }

    def _load_products(self) -> list[dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ embedding –∏–Ω–¥–µ–∫—Å–∞"""
        if self._products_cache is None:
            response = self.db.table('products').select('*').execute()
            self._products_cache = response.data or []
            # –°—Ç—Ä–æ–∏–º embedding –∏–Ω–¥–µ–∫—Å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            # ENABLE_ML_MATCHING=false –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—ç–∫–æ–Ω–æ–º–∏—Ç ~500 –ú–ë RAM)
            if settings.enable_ml_matching:
                if self._products_cache and not self._embedding_matcher.is_ready:
                    try:
                        logger.info("üîß –ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–∏ –¥–ª—è semantic matching...")
                        self._embedding_matcher.build_index(self._products_cache)
                        logger.info("‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è ML matching –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return self._products_cache

    def _load_client_mappings(self, client_id: UUID | None) -> dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞–ø–ø–∏–Ω–≥–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞ (thread-safe)"""
        if client_id is None:
            return {}  # –ë–µ–∑ client_id –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        client_key = str(client_id)
        # Thread-safe –¥–æ—Å—Ç—É–ø –∫ –∫—ç—à—É –º–∞–ø–ø–∏–Ω–≥–æ–≤
        with self._mappings_lock:
            if client_key not in self._mappings_cache:
                response = self.db.table('mappings')\
                    .select('client_sku, product_id, confidence, match_type')\
                    .eq('client_id', str(client_id))\
                    .eq('verified', True)\
                    .execute()
                self._mappings_cache[client_key] = {
                    normalize_sku(m['client_sku']): m
                    for m in (response.data or [])
                }
            return self._mappings_cache[client_key]

    def clear_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ (thread-safe)"""
        self._products_cache = None
        with self._mappings_lock:
            self._mappings_cache = {}

    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É matching"""
        stats = self._stats.copy()
        if stats['total'] > 0:
            stats['avg_confidence'] = round(
                stats['total_confidence'] / stats['total'], 1
            )
            stats['success_rate'] = round(
                100 * (stats['total'] - stats['not_found']) / stats['total'], 1
            )
        else:
            stats['avg_confidence'] = 0.0
            stats['success_rate'] = 0.0
        return stats

    def reset_stats(self):
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        for key in self._stats:
            self._stats[key] = 0 if isinstance(self._stats[key], int) else 0.0

    def _update_stats(self, match: MatchResult):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ match"""
        self._stats['total'] += 1
        self._stats['total_confidence'] += match.confidence
        if match.match_type in self._stats:
            self._stats[match.match_type] += 1

    def _finalize_match(self, match: MatchResult) -> MatchResult:
        """–§–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ + —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        self._update_stats(match)
        if match.product_id:
            logger.info(
                f"Matched: {match.match_type} @ {match.confidence:.0f}% "
                f"‚Üí {match.product_sku}"
            )
        else:
            logger.warning(f"Not found: {match.match_type}")
        return match

    def match_item(self, client_id: UUID | None, client_sku: str, client_name: str = None) -> MatchResult:
        """
        6-—É—Ä–æ–≤–Ω–µ–≤—ã–π –≥–∏–±—Ä–∏–¥–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞–ø–ø–∏–Ω–≥–∞ (v4.0):
        1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞ ‚Üí 100%
        2. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è ‚Üí 95%
        3. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ ‚Üí 100%
        4. Fuzzy SKU (Levenshtein dist ‚â§ 1) ‚Üí 90%
        5. –ì–∏–±—Ä–∏–¥–Ω—ã–π: pgvector TOP-30 ‚Üí fuzzy scoring ‚Üí —Ñ–∏–ª—å—Ç—Ä—ã ‚Üí 80%
        6. LLM verification (–µ—Å–ª–∏ confidence < 75%) ‚Üí ‚â§75%
        7. –ù–µ –Ω–∞–π–¥–µ–Ω–æ ‚Üí 0%
        """
        logger.debug(f"Matching: sku={client_sku!r}, name={client_name!r}")

        products = self._load_products()
        mappings = self._load_client_mappings(client_id)

        norm_sku = normalize_sku(client_sku)
        norm_name = normalize_name(client_name) if client_name else ""

        # Level 1: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞
        for product in products:
            if normalize_sku(product['sku']) == norm_sku:
                return self._finalize_match(MatchResult(
                    product_id=UUID(product['id']),
                    product_sku=product['sku'],
                    product_name=product['name'],
                    confidence=settings.confidence_exact_sku,
                    match_type="exact_sku",
                    needs_review=False,
                    pack_qty=product.get('pack_qty', 1)
                ))

        # Level 2: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        if norm_name:
            for product in products:
                if normalize_name(product['name']) == norm_name:
                    return self._finalize_match(MatchResult(
                        product_id=UUID(product['id']),
                        product_sku=product['sku'],
                        product_name=product['name'],
                        confidence=settings.confidence_exact_name,
                        match_type="exact_name",
                        needs_review=False,
                        pack_qty=product.get('pack_qty', 1)
                    ))

        # Level 3: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ (–ü–û–°–õ–ï —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π!)
        # –†–∞–Ω–µ–µ –±—ã–ª –ø–µ—Ä–≤—ã–º - —ç—Ç–æ –º–æ–≥–ª–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if norm_sku in mappings:
            mapping = mappings[norm_sku]
            product = next((p for p in products if str(p['id']) == str(mapping['product_id'])), None)
            if product:
                return self._finalize_match(MatchResult(
                    product_id=UUID(product['id']),
                    product_sku=product['sku'],
                    product_name=product['name'],
                    confidence=settings.confidence_exact_sku,
                    match_type="cached_mapping",
                    needs_review=False,
                    pack_qty=product.get('pack_qty', 1)
                ))

        # Level 4: Fuzzy SKU (Levenshtein distance ‚â§ 1)
        best_sku_match = None
        best_sku_ratio = 0
        for product in products:
            prod_norm_sku = normalize_sku(product['sku'])
            ratio = fuzz.ratio(norm_sku, prod_norm_sku)
            if ratio > best_sku_ratio and ratio >= 90:
                best_sku_ratio = ratio
                best_sku_match = product

        if best_sku_match and best_sku_ratio >= 90:
            return self._finalize_match(MatchResult(
                product_id=UUID(best_sku_match['id']),
                product_sku=best_sku_match['sku'],
                product_name=best_sku_match['name'],
                confidence=settings.confidence_fuzzy_sku * (best_sku_ratio / 100),
                match_type="fuzzy_sku",
                needs_review=best_sku_ratio < 95,
                pack_qty=best_sku_match.get('pack_qty', 1)
            ))

        # Level 5: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (pgvector + fuzzy + —Ñ–∏–ª—å—Ç—Ä—ã)
        if norm_name:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            client_size = extract_pipe_size(client_name or "")
            client_fitting_size = extract_fitting_size(client_name or "")
            client_thread_size = extract_thread_size(client_name or "")
            client_cat = detect_client_category(client_name or "")
            client_type = extract_product_type(client_name or "")
            client_angle = extract_angle(client_name or "")
            clamp_mm = extract_mm_from_clamp(client_name or "")
            client_wants_eco = is_eco_product(client_name or "")
            client_is_detachable = is_coupling_detachable(client_name or "")
            client_is_reducer = is_reducer(client_name or "")

            # Level 5: Full scan —Å fuzzy matching + —Ñ–∏–ª—å—Ç—Ä—ã
            # NOTE: pgvector –æ—Ç–∫–ª—é—á—ë–Ω - embeddings –≤ –ë–î —É—Å—Ç–∞—Ä–µ–ª–∏ –∏ —Ç—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ—Å—á—ë—Ç–∞
            # TODO: –ø–æ—Å–ª–µ –ø–µ—Ä–µ—Å—á—ë—Ç–∞ embeddings –≤–µ—Ä–Ω—É—Ç—å pgvector –∫–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            search_products = products

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ —Å fuzzy scoring
            matches = []
            for product in search_products:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—á–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Ç—Ä—É–± (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
                if client_size:
                    product_size = extract_pipe_size(product['name'])
                    if product_size and product_size != client_size:
                        continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ä–µ–∑—å–±—ã (25x1" ‚â† 20x1/2")
                if client_thread_size:
                    product_thread = extract_thread_size(product['name'])
                    if product_thread and product_thread != client_thread_size:
                        continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∏—Ç–∏–Ω–≥–∞ (–º—É—Ñ—Ç–∞ 25 ‚â† –º—É—Ñ—Ç–∞ 50)
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã: (25, 25) ‚Üí (25,), (20, 20, 20) ‚Üí (20,)
                # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –ü–ù–î –≥–¥–µ "–û—Ç–≤–æ–¥ 25-25" = "–û—Ç–≤–æ–¥ 25" –≤ –∫–∞—Ç–∞–ª–æ–≥–µ
                if client_fitting_size:
                    product_fitting = extract_fitting_size(product['name'])
                    if product_fitting:
                        norm_client = normalize_equal_sizes(client_fitting_size)
                        norm_product = normalize_equal_sizes(product_fitting)

                        if len(norm_client) == 1:
                            # –û–¥–∏–Ω —Ä–∞–∑–º–µ—Ä - –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π —Ä–∞–∑–º–µ—Ä –∫–∞—Ç–∞–ª–æ–≥–∞
                            if norm_product[0] != norm_client[0]:
                                continue
                        elif norm_product != norm_client:
                            # –†–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã (–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫–∏) - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                            continue

                prod_norm_name = normalize_name(product['name'])
                ratio = max(
                    fuzz.token_sort_ratio(norm_name, prod_norm_name),
                    fuzz.token_set_ratio(norm_name, prod_norm_name)
                )
                if ratio >= settings.fuzzy_threshold:
                    matches.append((product, ratio))

            if matches:
                # –í–ê–ñ–ù–û: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã –∫–æ –í–°–ï–ú matches,
                # –ø–æ—Ç–æ–º –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏—Ö. –ò–Ω–∞—á–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø –º–æ–∂–µ—Ç –∏–º–µ—Ç—å
                # –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π score –∏ –≤—ã—Ç–µ—Å–Ω–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.
                client_thread = extract_thread_type(client_name or "")

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É —Ç–æ–≤–∞—Ä–∞ - –ñ–Å–°–¢–ö–ò–ô –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–∏–ø–æ–≤
                # –ö—Ä–∞–Ω –ù–ò–ö–û–ì–î–ê –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –û—Ç–≤–æ–¥–æ–º, –ú—É—Ñ—Ç–∞ —Å –¢—Ä–æ–π–Ω–∏–∫–æ–º –∏ —Ç.–¥.
                CRITICAL_TYPES = {"–∫—Ä–∞–Ω", "–º—É—Ñ—Ç–∞", "–æ—Ç–≤–æ–¥", "—Ç—Ä–æ–π–Ω–∏–∫", "–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫", "–∑–∞–≥–ª—É—à–∫–∞", "—Ä–µ–≤–∏–∑–∏—è", "–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω–∞"}
                if client_type:
                    type_filtered = [m for m in matches
                                     if extract_product_type(m[0]['name']) == client_type]
                    if type_filtered:
                        matches = type_filtered
                    elif client_type in CRITICAL_TYPES:
                        # –¢–∏–ø –∫—Ä–∏—Ç–∏—á–µ–Ω –∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–∞—Ç–∞–ª–æ–≥–µ - –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–æ–∂–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        logger.debug(f"–¢–∏–ø '{client_type}' –∫—Ä–∏—Ç–∏—á–µ–Ω, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ matches - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º fuzzy")
                        matches = []

                # –§–∏–ª—å—Ç—Ä –ø–æ —É–≥–ª—É - –ø—Ä–∏–º–µ–Ω—è–µ–º –∫–æ –≤—Å–µ–º (—Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π 90¬∞ ‚Üí 87¬∞)
                if client_angle:
                    normalized_angle = normalize_angle(client_angle)
                    if normalized_angle:  # None = —É–≥–æ–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (30¬∞ –≤ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
                        angle_filtered = [m for m in matches
                                          if extract_angle(m[0]['name']) == normalized_angle]
                        if angle_filtered:
                            matches = angle_filtered

                # –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ - –ø—Ä–∏–º–µ–Ω—è–µ–º –∫–æ –í–°–ï–ú matches (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –º—É—Ñ—Ç)
                # –ò–Ω–∞—á–µ 604 (—Ä–∏—Ñ–ª–µ–Ω—ã–µ) –º–æ–≥—É—Ç –∏–º–µ—Ç—å –≤—ã—à–µ score —á–µ–º 202 (–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è)
                # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞ - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'sewer' (—Å–µ—Ä–∞—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è)
                effective_cat = client_cat or 'sewer'
                cat_filtered = filter_by_category(matches, effective_cat)
                if cat_filtered:
                    matches = cat_filtered

                # –ö–†–ò–¢–ò–ß–ù–û: —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ —Ä–∞–∑—ä–µ–º–Ω—ã–º/–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫–∞–º –î–û —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                # –ò–Ω–∞—á–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è (–º—É—Ñ—Ç–∞ 20) –ø–æ–ª—É—á–∞—é—Ç –≤—ã—à–µ score —á–µ–º –¥–ª–∏–Ω–Ω—ã–µ
                if client_is_detachable:
                    det_filtered = [m for m in matches
                                    if is_coupling_detachable(m[0]['name'])]
                    if det_filtered:
                        matches = det_filtered

                if client_is_reducer:
                    red_filtered = [m for m in matches
                                    if is_reducer(m[0]['name'])]
                    if red_filtered:
                        matches = red_filtered

                # –¢–µ–ø–µ—Ä—å —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä—ë–º top
                matches.sort(key=lambda x: x[1], reverse=True)
                best_ratio = matches[0][1]
                top_matches = [m for m in matches if m[1] >= best_ratio - 2]

                # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ñ–∏–ª—å—Ç—Ä—ã
                top_matches = filter_by_thread(top_matches, client_thread)

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º —Ñ–∏—Ç–∏–Ω–≥–æ–≤ (110/50 vs 110/110)
                top_matches = filter_by_fitting_size(top_matches, client_fitting_size)

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ä–µ–∑—å–±—ã (32√ó1" –¥–ª—è –º—É—Ñ—Ç –ù–†/–í–†)
                top_matches = filter_by_thread_size(top_matches, client_thread_size)

                # –•–æ–º—É—Ç—ã - —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –º–º
                if clamp_mm and len(top_matches) > 1:
                    fitting = [m for m in top_matches
                               if clamp_fits_mm(m[0]['name'], clamp_mm)]
                    if fitting:
                        top_matches = fitting

                # –ï—Å–ª–∏ –ù–ï –≠–ö–û - –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç
                if not client_wants_eco and len(top_matches) > 1:
                    non_eco = [m for m in top_matches
                               if not is_eco_product(m[0]['name'])]
                    if non_eco:
                        top_matches = non_eco

                # GUARD: –ï—Å–ª–∏ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –æ—Ç—Å–µ—è–ª–∏ matches - fallback –Ω–∞ LLM
                if not top_matches:
                    logger.debug(f"–í—Å–µ fuzzy matches –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –¥–ª—è '{client_name}' - fallback –Ω–∞ LLM")
                    llm = get_llm_matcher()
                    if llm:
                        if not llm.is_ready:
                            llm.set_products(products)
                        llm_result = llm.match(client_name)
                        if llm_result and llm_result.get("sku"):
                            llm_product = next(
                                (p for p in products if p["sku"] == llm_result["sku"]),
                                None
                            )
                            if llm_product:
                                return self._finalize_match(MatchResult(
                                    product_id=UUID(llm_product['id']),
                                    product_sku=llm_product['sku'],
                                    product_name=llm_product['name'],
                                    confidence=float(llm_result.get("confidence", 70)),
                                    match_type="llm_match",
                                    needs_review=True,
                                    pack_qty=llm_product.get('pack_qty', 1)
                                ))
                    # LLM –Ω–µ –ø–æ–º–æ–≥ - not_found
                    return self._finalize_match(MatchResult(
                        product_id=None, product_sku=None, product_name=None,
                        confidence=0.0, match_type="not_found", needs_review=True
                    ))

                best_match, best_ratio = top_matches[0]
                conf = settings.confidence_fuzzy_name * (best_ratio / 100)
                if len(matches) > 1 and not client_wants_eco:
                    conf = min(conf + 5, 95.0)

                # –ï—Å–ª–∏ confidence –Ω–∏–∑–∫–∏–π (<75%) - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á–µ—Ä–µ–∑ LLM
                if conf < 75:
                    llm = get_llm_matcher()
                    if llm:
                        if not llm.is_ready:
                            llm.set_products(products)
                        llm_result = llm.match(client_name)
                        if llm_result and llm_result.get("sku"):
                            llm_conf = float(llm_result.get("confidence", 0))
                            if llm_conf > conf:
                                llm_product = next(
                                    (p for p in products
                                     if p["sku"] == llm_result["sku"]),
                                    None
                                )
                                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–∏—Ç–∏–Ω–≥–∞
                                if llm_product and client_fitting_size:
                                    product_size = extract_fitting_size(llm_product['name'])
                                    if product_size and product_size != client_fitting_size:
                                        logger.debug(f"LLM L6 size mismatch: {client_fitting_size} vs {product_size}")
                                        llm_product = None
                                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞ (–∫—Ä–∞–Ω ‚â† –æ—Ç–≤–æ–¥, –∑–∞–≥–ª—É—à–∫–∞ ‚â† –º—É—Ñ—Ç–∞)
                                if llm_product and client_type and client_type in CRITICAL_TYPES:
                                    product_t = extract_product_type(llm_product['name'])
                                    if product_t and product_t != client_type:
                                        logger.debug(f"LLM L6 type mismatch: {client_type} vs {product_t}")
                                        llm_product = None
                                if llm_product:
                                    return self._finalize_match(MatchResult(
                                        product_id=UUID(llm_product['id']),
                                        product_sku=llm_product['sku'],
                                        product_name=llm_product['name'],
                                        confidence=llm_conf,
                                        match_type="llm_match",
                                        needs_review=llm_conf < 80,
                                        pack_qty=llm_product.get('pack_qty', 1)
                                    ))

                return self._finalize_match(MatchResult(
                    product_id=UUID(best_match['id']),
                    product_sku=best_match['sku'],
                    product_name=best_match['name'],
                    confidence=conf,
                    match_type="fuzzy_name",
                    needs_review=conf < settings.min_confidence_auto,
                    pack_qty=best_match.get('pack_qty', 1)
                ))

        # Level 7: LLM matching —á–µ—Ä–µ–∑ OpenRouter API
        llm = get_llm_matcher()
        if llm and client_name:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—Ç–∞–ª–æ–≥ –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
            if not llm.is_ready:
                llm.set_products(products)

            result = llm.match(client_name)
            if result and result.get("sku"):
                # –ò—â–µ–º —Ç–æ–≤–∞—Ä –ø–æ SKU –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
                product = next(
                    (p for p in products if p["sku"] == result["sku"]),
                    None
                )
                if product:
                    # Post-validation: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã
                    # 1. –†–∞–∑–º–µ—Ä —Ç—Ä—É–±—ã (110√ó2000 ‚â† 110√ó3000)
                    client_size = extract_pipe_size(client_name)
                    if client_size:
                        product_size = extract_pipe_size(product['name'])
                        if product_size and product_size != client_size:
                            logger.debug(f"LLM L7 pipe size mismatch: {client_size} vs {product_size}")
                            product = None

                    # 2. –†–∞–∑–º–µ—Ä —Ñ–∏—Ç–∏–Ω–≥–∞ (–º—É—Ñ—Ç–∞ 25 ‚â† –º—É—Ñ—Ç–∞ 50)
                    if product:
                        client_fitting = extract_fitting_size(client_name)
                        if client_fitting:
                            product_fitting = extract_fitting_size(product['name'])
                            if product_fitting and product_fitting != client_fitting:
                                logger.debug(f"LLM L7 fitting size mismatch: {client_fitting} vs {product_fitting}")
                                product = None

                    # 3. –†–∞–∑–º–µ—Ä —Ä–µ–∑—å–±—ã (32√ó1" ‚â† 25√ó3/4")
                    if product:
                        client_thread = extract_thread_size(client_name)
                        if client_thread:
                            product_thread = extract_thread_size(product['name'])
                            if product_thread and product_thread != client_thread:
                                logger.debug(f"LLM L7 thread size mismatch: {client_thread} vs {product_thread}")
                                product = None

                    # 4. –¢–∏–ø —Ç–æ–≤–∞—Ä–∞ - –ö–†–ò–¢–ò–ß–ï–ù (–∫—Ä–∞–Ω ‚â† –æ—Ç–≤–æ–¥, –∑–∞–≥–ª—É—à–∫–∞ ‚â† –º—É—Ñ—Ç–∞)
                    if product:
                        CRITICAL_TYPES = {"–∫—Ä–∞–Ω", "–º—É—Ñ—Ç–∞", "–æ—Ç–≤–æ–¥", "—Ç—Ä–æ–π–Ω–∏–∫", "–ø–µ—Ä–µ—Ö–æ–¥–Ω–∏–∫", "–∑–∞–≥–ª—É—à–∫–∞", "—Ä–µ–≤–∏–∑–∏—è", "–∫—Ä–µ—Å—Ç–æ–≤–∏–Ω–∞"}
                        client_type = extract_product_type(client_name)
                        if client_type and client_type in CRITICAL_TYPES:
                            product_type = extract_product_type(product['name'])
                            if product_type and product_type != client_type:
                                logger.debug(f"LLM L7 type mismatch: {client_type} vs {product_type}")
                                product = None

                if product:
                    conf = float(result.get("confidence", 70))
                    return self._finalize_match(MatchResult(
                        product_id=UUID(product['id']),
                        product_sku=product['sku'],
                        product_name=product['name'],
                        confidence=conf,
                        match_type="llm_match",
                        needs_review=conf < 80,
                        pack_qty=product.get('pack_qty', 1)
                    ))

        # Level 7: –ù–µ –Ω–∞–π–¥–µ–Ω–æ - —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        return self._finalize_match(MatchResult(
            product_id=None,
            product_sku=None,
            product_name=None,
            confidence=0.0,
            match_type="not_found",
            needs_review=True
        ))

    def match_order_items(self, client_id: UUID, items: list[dict],
                          auto_save: bool = True) -> list[dict]:
        """
        –ú–∞–ø–ø–∏–Ω–≥ –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π –∑–∞–∫–∞–∑–∞.

        Args:
            client_id: ID –∫–ª–∏–µ–Ω—Ç–∞
            items: –°–ø–∏—Å–æ–∫ –ø–æ–∑–∏—Ü–∏–π –∑–∞–∫–∞–∑–∞
            auto_save: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–∞–ø–ø–∏–Ω–≥–∏ —Å –≤—ã—Å–æ–∫–∏–º confidence
        """
        results = []
        for item in items:
            client_sku = item.get('client_sku', '')
            match = self.match_item(
                client_id=client_id,
                client_sku=client_sku,
                client_name=item.get('client_name', '')
            )

            # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω—ã—Ö –º–∞–ø–ø–∏–Ω–≥–æ–≤
            auto_saved = False
            if auto_save and client_sku:
                auto_saved = self.auto_save_high_confidence(client_id, client_sku, match)

            results.append({
                **item,
                'match': match.model_dump(),
                'auto_saved': auto_saved
            })
        return results

    def save_mapping(self, client_id: UUID, client_sku: str, product_id: UUID,
                     confidence: float, match_type: str, verified: bool = False):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –≤ –ë–î"""
        data = {
            'client_id': str(client_id),
            'client_sku': client_sku,
            'product_id': str(product_id),
            'confidence': confidence,
            'match_type': match_type,
            'verified': verified
        }

        # Upsert - –æ–±–Ω–æ–≤–ª—è–µ–º –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self.db.table('mappings').upsert(
            data,
            on_conflict='client_id,client_sku'
        ).execute()

        # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à
        client_key = str(client_id)
        if client_key in self._mappings_cache:
            del self._mappings_cache[client_key]

    def auto_save_high_confidence(self, client_id: UUID, client_sku: str,
                                   match: MatchResult) -> bool:
        """
        –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º confidence (‚â•95%).
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞–∫ unverified - —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è.

        Returns:
            True –µ—Å–ª–∏ –º–∞–ø–ø–∏–Ω–≥ –±—ã–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω
        """
        if (match.confidence >= settings.confidence_exact_name and
            match.product_id is not None and
            match.match_type in ("exact_sku", "exact_name", "cached_mapping")):
            try:
                self.save_mapping(
                    client_id=client_id,
                    client_sku=client_sku,
                    product_id=match.product_id,
                    confidence=match.confidence,
                    match_type=match.match_type,
                    verified=False  # –¢—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                )
                return True
            except Exception:
                pass
        return False
