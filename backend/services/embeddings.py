"""
Embedding-based semantic matching service.
Level 7 Ð² Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ðµ Ð¼Ð°Ð¿Ð¿Ð¸Ð½Ð³Ð° - ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾ Ñ‡ÐµÑ€ÐµÐ· pgvector.

v5.0: Ð—Ð°Ð¼ÐµÐ½Ñ‘Ð½ FAISS Ð½Ð° pgvector (embeddings Ñ…Ñ€Ð°Ð½ÑÑ‚ÑÑ Ð² PostgreSQL)
v6.0: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ OpenAI API (via OpenRouter) Ð²Ð¼ÐµÑÑ‚Ð¾ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÑÐ½Ð¸Ð¶ÐµÐ½Ð¸Ñ RAM (0 MB).
"""

import logging
import time

from backend.models.database import get_supabase_client
from backend.utils.matching_helpers import prepare_embedding_text
from fastembed import TextEmbedding

logger = logging.getLogger(__name__)


class EmbeddingMatcher:
    """Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ñ‡ÐµÑ€ÐµÐ· FastEmbed (ONNX Local) + pgvector.
    Ð’ÐµÐºÑ‚Ð¾Ñ€: 384 dimensions (model: paraphrase-multilingual-MiniLM-L12-v2)
    """

    def __init__(self):
        self.db = get_supabase_client()
        logger.info(
            "ðŸ“¥ Loading FastEmbed model (sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)..."
        )
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÑÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸)
        self.model = TextEmbedding(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        self._initialized = True

    def build_index(self, products: list[dict]) -> None:
        pass

    def search(
        self, query: str, top_k: int = 5, min_score: float = 0.5
    ) -> list[tuple[dict, float]]:
        """
        Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð².
        """
        # 1. ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð°
        embedding_text = prepare_embedding_text(query)
        if not embedding_text:
            return []

        # 2. Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· FastEmbed (Ð±Ñ‹ÑÑ‚Ñ€Ð°Ñ, CPU)
        try:
            # list(generate) Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð² (Ð½Ð°Ð¼ Ð½ÑƒÐ¶ÐµÐ½ Ð¿ÐµÑ€Ð²Ñ‹Ð¹)
            embeddings = list(self.model.embed([embedding_text]))
            query_embedding = embeddings[0].tolist()
        except Exception as e:
            logger.error(f"FastEmbed generation failed: {e}")
            return []

        # 3. ÐŸÐ¾Ð¸ÑÐº Ð² Ð‘Ð”
        try:
            result = self.db.rpc(
                "match_products",
                {
                    "query_embedding": query_embedding,
                    "match_threshold": min_score,
                    "match_count": top_k,
                },
            ).execute()

            matches = []
            for row in result.data:
                product = {
                    "id": row["id"],
                    "sku": row["sku"],
                    "name": row["name"],
                }
                matches.append((product, row["similarity"]))

            return matches

        except Exception as e:
            logger.error(f"pgvector search error: {e}")
            return []

    def get_best_match(
        self, query: str, min_score: float = 0.6
    ) -> tuple[dict, float] | None:
        results = self.search(query, top_k=1, min_score=min_score)
        return results[0] if results else None

    @property
    def is_ready(self) -> bool:
        return self._initialized


# Singleton
_embedding_matcher: EmbeddingMatcher | None = None


def get_embedding_matcher() -> EmbeddingMatcher:
    global _embedding_matcher
    if _embedding_matcher is None:
        _embedding_matcher = EmbeddingMatcher()
    return _embedding_matcher
