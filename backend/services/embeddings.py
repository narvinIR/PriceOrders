"""
Embedding-based semantic matching service.
Level 7 Ð² Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ðµ Ð¼Ð°Ð¿Ð¿Ð¸Ð½Ð³Ð° - ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾ Ñ‡ÐµÑ€ÐµÐ· pgvector.

v5.0: Ð—Ð°Ð¼ÐµÐ½Ñ‘Ð½ FAISS Ð½Ð° pgvector (embeddings Ñ…Ñ€Ð°Ð½ÑÑ‚ÑÑ Ð² PostgreSQL)
v6.0: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ OpenAI API (via OpenRouter) Ð²Ð¼ÐµÑÑ‚Ð¾ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÑÐ½Ð¸Ð¶ÐµÐ½Ð¸Ñ RAM (0 MB).
"""

import logging
import time

from backend.models.database import get_supabase_client
from backend.utils.matching_helpers import prepare_embedding_text

# Local ML Model
from sentence_transformers import SentenceTransformer

logger = logging.getLogger(__name__)


class EmbeddingMatcher:
    """Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· pgvector (PostgreSQL) + Local Embeddings (rubert-tiny2)"""

    def __init__(self):
        self.db = get_supabase_client()
        logger.info("ðŸ“¥ Loading local embedding model (cointegrated/rubert-tiny2)...")
        self.model = SentenceTransformer("cointegrated/rubert-tiny2")
        self._initialized = True

    def build_index(self, products: list[dict]) -> None:
        """
        DEPRECATED: Ð˜Ð½Ð´ÐµÐºÑ Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð² PostgreSQL (HNSW).
        """
        pass

    def search(
        self, query: str, top_k: int = 5, min_score: float = 0.5
    ) -> list[tuple[dict, float]]:
        """
        Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· pgvector.

        Args:
            query: Ð¢ÐµÐºÑÑ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° (Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð°)
            top_k: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
            min_score: ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð° (0-1)

        Returns:
            Ð¡Ð¿Ð¸ÑÐ¾Ðº (product, score) Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾ ÑƒÐ±Ñ‹Ð²Ð°Ð½Ð¸ÑŽ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð°
        """
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐµÐ´Ð¸Ð½ÑƒÑŽ Ð»Ð¾Ð³Ð¸ÐºÑƒ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°
        embedding_text = prepare_embedding_text(query)
        if not embedding_text:
            return []

        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ embedding Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾
        try:
            query_embedding = self.model.encode(embedding_text).tolist()
        except Exception as e:
            logger.error(f"Local embedding generation failed: {e}")
            return []

        # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ RPC Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ match_products Ð² PostgreSQL
        try:
            result = self.db.rpc(
                "match_products",
                {
                    "query_embedding": query_embedding,
                    "match_threshold": min_score,
                    "match_count": top_k,
                },
            ).execute()

            # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ (product, score)
            matches = []
            for row in result.data:
                product = {
                    "id": row["id"],
                    "sku": row["sku"],
                    "name": row["name"],
                }
                matches.append((product, row["similarity"]))

            return matches

        except Exception as e:
            logger.error(f"pgvector search error: {e}")
            return []

    def get_best_match(
        self, query: str, min_score: float = 0.6
    ) -> tuple[dict, float] | None:
        results = self.search(query, top_k=1, min_score=min_score)
        return results[0] if results else None

    @property
    def is_ready(self) -> bool:
        return self._initialized


# Singleton
_embedding_matcher: EmbeddingMatcher | None = None


def get_embedding_matcher() -> EmbeddingMatcher:
    global _embedding_matcher
    if _embedding_matcher is None:
        _embedding_matcher = EmbeddingMatcher()
    return _embedding_matcher
